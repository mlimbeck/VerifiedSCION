// Copyright 2022 ETH Zurich
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//   http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// +gobra

package router

import (
	"net"
	"hash"
	sl "github.com/scionproto/scion/verification/utils/slices"
	"github.com/scionproto/scion/verification/io"
	"github.com/scionproto/scion/verification/dependencies/encoding/binary"
	"github.com/scionproto/scion/verification/utils/bitwise"
	"github.com/scionproto/scion/pkg/scrypto"
	"github.com/scionproto/scion/pkg/addr"
)

// TODO: maybe change interpretation of Mutex depending on whether the
// dataplane is running or not. This is because, when Run is called and
// d.running is set to true, the permissions to some of these fields is transferred
// to the read closure, and thus, we cannot transfer it back on the call to unlock
// at the end of run
pred MutexInvariant(d *DataPlane) {
	// access to the field 'mtx' ommited
	acc(&d.external,          1/2) &&
	acc(&d.linkTypes,         1/2) &&
	acc(&d.neighborIAs,       1/2) &&
	acc(&d.internal,          1/2) &&
	acc(&d.internalIP,        1/2) &&
	acc(&d.internalNextHops,  1/2) &&
	acc(&d.svc,               1/2) &&
	acc(&d.macFactory,        1/2) &&
	acc(&d.bfdSessions,       1/2) &&
	acc(&d.localIA,           1/2) &&
	acc(&d.running,           1/2) &&
	acc(&d.Metrics,           1/2) &&
	acc(&d.forwardingMetrics, 1/2) &&
	acc(&d.key,               1/2) &&
	(d.external    != nil       ==> AccBatchConn(d.external))           &&
	(d.linkTypes   != nil       ==> acc(d.linkTypes, 1/2))              &&
	(d.neighborIAs != nil       ==> acc(d.neighborIAs, 1/2))            &&
	(d.internal != nil          ==> d.internal.Mem())                   &&
	(d.internalIP != nil        ==> d.internalIP.Mem())                 &&
	(d.internalNextHops != nil  ==> AccAddr(d.internalNextHops))        &&
	(d.svc != nil               ==> acc(d.svc.Mem(), _))                &&
	(d.macFactory != nil        ==> acc(d.key, 1/2))                    &&
	(d.macFactory != nil        ==> acc(sl.AbsSlice_Bytes(*d.key, 0, len(*d.key)), _)) &&
	(d.macFactory != nil        ==> scrypto.ValidKeyForHash(*d.key)) &&
	(d.macFactory != nil        ==> d.macFactory implements MacFactorySpec{d.key}) &&
	(d.bfdSessions != nil       ==> AccBfdSession(d.bfdSessions))       &&
	(d.Metrics != nil           ==> acc(d.Metrics.Mem(), _))            &&
	// The following permissions are enough to call all methods needed in fields
	// of forwardingMetrics
	(d.forwardingMetrics != nil ==> AccForwardingMetrics(d.forwardingMetrics))
}

// TODO: reorganize permissions consistently

// TODO: use lower case for these predicates' names?
// TODO: drop wildcards here
pred AccAddr(addrs map[uint16]*net.UDPAddr) {
	acc(addrs, 1/2) &&
	forall a *net.UDPAddr :: { a in range(addrs) } a in range(addrs) ==> acc(a.Mem(), _)
}

pred AccBatchConn(batchConns map[uint16]BatchConn) {
	acc(batchConns, 1/2) &&
	forall b BatchConn :: b in range(batchConns) ==> b.Mem()
}

// TODO: drop wildcards here
pred AccBfdSession(bfdSessions map[uint16]bfdSession) {
	acc(bfdSessions, 1/2) &&
	(forall bfd bfdSession :: { bfd in range(bfdSessions) } bfd in range(bfdSessions) ==> (bfd != nil && acc(bfd.Mem(), _)))
}

// TODO: drop wildcards here
pred AccForwardingMetrics(metrics map[uint16]forwardingMetrics) {
	acc(metrics, 1/2) &&
	forall id uint16 :: { metrics[id] } id in domain(metrics) ==> acc(forwardingMetricsMem(metrics[id], id), _)
}

pred forwardingMetricsMem(v forwardingMetrics, ignoredForInjectivity uint16) {
	v.InputBytesTotal.Mem()      &&
	v.OutputBytesTotal.Mem()     &&
	v.InputPacketsTotal.Mem()    &&
	v.OutputPacketsTotal.Mem()   &&
	v.DroppedPacketsTotal.Mem()
}

pred forwardingMetricsNonInjectiveMem(v forwardingMetrics) {
	v.InputBytesTotal.Mem()      &&
	v.OutputBytesTotal.Mem()     &&
	v.InputPacketsTotal.Mem()    &&
	v.OutputPacketsTotal.Mem()   &&
	v.DroppedPacketsTotal.Mem()
}

ghost
requires  acc(forwardingMetricsNonInjectiveMem(v), _)
ensures   acc(forwardingMetricsMem(v, id), _)
decreases
func liftForwardingMetricsNonInjectiveMem(v forwardingMetrics, id uint16) {
	unfold acc(forwardingMetricsNonInjectiveMem(v), _)
	fold acc(forwardingMetricsMem(v, id), _)
}

pred (p *scionPacketProcessor) initMem() {
	acc(&p.d) &&
	acc(&p.ingressID) &&
	acc(&p.buffer) &&
	acc(&p.mac) &&
	acc(p.scionLayer.NonInitMem()) &&
	p.scionLayer.PathPoolInitializedNonInitMem() &&
	acc(&p.hbhLayer) &&
	acc(&p.e2eLayer) &&
	acc(&p.lastLayer) &&
	acc(&p.path) &&
	acc(&p.hopField) &&
	acc(&p.infoField) &&
	acc(&p.segmentChange) &&
	acc(&p.cachedMac) &&
	acc(&p.macBuffers) &&
	acc(&p.bfdLayer)
}

requires acc(key, _) && acc(sl.AbsSlice_Bytes(*key, 0, len(*key)), _)
requires scrypto.ValidKeyForHash(*key)
ensures  acc(key, _) && acc(sl.AbsSlice_Bytes(*key, 0, len(*key)), _)
ensures  res.Mem()
decreases
func MacFactorySpec(ghost key *[]byte) (res hash.Hash)

// useful to deal with incompletnesses
pred hideLocalIA(p *addr.IA) {
	acc(p)
}

pred (err scmpError) ErrorMem() {
	err.Cause != nil ==> err.Cause.ErrorMem()
}

// Currently assumed, as Gobra cannot currently prove termination
// of the code below
ghost
trusted
pure
decreases
func (err scmpError) IsDuplicableMem() bool {
	return err != nil? err.cause.IsDuplicableMem() : true
}

// Currently assumed, as Gobra cannot currently prove termination
// of the code below
ghost
trusted
preserves err.ErrorMem()
ensures   err.IsDuplicableMem() ==> err.ErrorMem()
decreases
func (err scmpError) Duplicate() {
	if err.IsDuplicableMem() {
		unfold err.ErrorMem()
		err.cause.Duplicate()
		fold err.ErrorMem()
	}
}

scmpError implements error

type offsetPair struct {
	start int
	end int
	isNil bool
}

ghost
pure
requires 0 <= n
ensures  len(res) == n
ensures  forall i int :: {res[i]} 0 <= i && i < len(res) ==> res[i] == offsetPair{}
decreases
func newOffsetPair(n int) (res seq[offsetPair])

/**** Acessor methods to avoid unfolding the Mem predicate of the dataplane so much ****/
ghost
requires acc(MutexInvariant!<d!>(), _)
ensures  acc(&d.internalNextHops, _)
ensures  d.internalNextHops != nil ==> acc(AccAddr(d.internalNextHops), _)
decreases
func (d *DataPlane) getInternalNextHops() {
	unfold acc(MutexInvariant!<d!>(), _)
}

ghost
requires acc(MutexInvariant!<d!>(), _)
ensures  acc(&d.external, _) && (d.external != nil ==> acc(AccBatchConn(d.external), _))
decreases
func (d *DataPlane) getExternalMem() {
	unfold acc(MutexInvariant!<d!>(), _)
}

ghost
requires acc(MutexInvariant!<d!>(), _)
ensures  acc(&d.linkTypes, _) && (d.linkTypes != nil ==> acc(d.linkTypes, _))
decreases
func (d *DataPlane) getLinkTypesMem() {
	unfold acc(MutexInvariant!<d!>(), _)
}

ghost
requires acc(MutexInvariant!<d!>(), _)
ensures  acc(&d.localIA, _)
decreases
func (d *DataPlane) getLocalIA() {
	unfold acc(MutexInvariant!<d!>(), _)
}

ghost
requires acc(MutexInvariant!<d!>(), _)
ensures  acc(&d.neighborIAs, _) && (d.neighborIAs != nil ==> acc(d.neighborIAs, _))
decreases
func (d *DataPlane) getNeighborIAs() {
	unfold acc(MutexInvariant!<d!>(), _)
}

ghost
requires acc(MutexInvariant!<d!>(), _)
ensures  acc(&d.svc, _) && (d.svc != nil ==> acc(d.svc.Mem(), _))
decreases
func (d *DataPlane) getSvcMem() {
	unfold acc(MutexInvariant!<d!>(), _)
}

ghost
requires acc(MutexInvariant!<d!>(), _)
ensures  acc(&d.bfdSessions, _) && (d.bfdSessions != nil ==> acc(AccBfdSession(d.bfdSessions), _))
decreases
func (d *DataPlane) getBfdSessionsMem() {
	unfold acc(MutexInvariant!<d!>(), _)
}

ghost
requires acc(MutexInvariant!<d!>(), _)
ensures  acc(&d.internal, _) && (d.internal != nil ==> acc(d.internal.Mem(), _))
decreases
func (d *DataPlane) getInternal() {
	unfold acc(MutexInvariant!<d!>(), _)
}

requires acc(MutexInvariant!<d!>(), _)
ensures  acc(&d.macFactory, _)
decreases
func (d *DataPlane) getMacFactoryMem() {
	unfold acc(MutexInvariant!<d!>(), _)
}

ghost
requires acc(MutexInvariant!<d!>(), _)
requires acc(&d.macFactory, _) && d.macFactory != nil
ensures  acc(&d.macFactory, _) && acc(&d.key, _) && acc(d.key, _)
ensures  acc(sl.AbsSlice_Bytes(*d.key, 0, len(*d.key)), _)
ensures  scrypto.ValidKeyForHash(*d.key)
ensures  d.macFactory implements MacFactorySpec{d.key}
decreases
func (d *DataPlane) getNewPacketProcessorFootprint() {
	unfold acc(MutexInvariant!<d!>(), _)
}

/**** End of acessor methods to avoid unfolding the Mem predicate of the dataplane so much ****/

/**** Post-init invariants ****/

// unsupportedPathType is duplicable: we can always establish its invariant
ghost
ensures unsupportedPathType.ErrorMem()
decreases _
func establishMemUnsupportedPathType()

// malformedPath is duplicable: we can always establish its invariant
ghost
ensures malformedPath != nil
ensures malformedPath.ErrorMem()
decreases _
func establishMemMalformedPath()

// unsupportedPathTypeNextHeader is duplicable: we can always establish its invariant
ghost
ensures unsupportedPathTypeNextHeader.ErrorMem()
decreases _
func establishMemUnsupportedPathTypeNextHeader()

// noBFDSessionConfigured is duplicable: we can always establish its invariant
ghost
ensures noBFDSessionConfigured.ErrorMem()
decreases _
func establishMemNoBFDSessionConfigured()

// noBFDSessionFound is duplicable: we can always establish its invariant
ghost
ensures noBFDSessionFound.ErrorMem()
decreases _
func establishMemNoBFDSessionFound()

// invalidSrdAddrForTransit is duplicable: we can always establish its invariant
ghost
ensures invalidSrcAddrForTransit.ErrorMem()
decreases _
func establishInvalidSrcAddrForTransit()

// noSVCBackend is duplicable: we can always establish its invariant
ghost
ensures noSVCBackend.ErrorMem()
decreases _
func establishNoSVCBackend()

// cannotRoute is duplicable: we can always establish its invariant after init
ghost
ensures cannotRoute.ErrorMem()
decreases _
func establishCannotRoute()

/**** End of post-init invariants ****/

/** Start of closure specs for the Run method **/
requires true
func readClosureSpec(ingressID uint16, rd BatchConn)

requires true
func closureSpec1(ifID uint16, c bfdSession)

requires true
func closureSpec2(i uint16, c BatchConn)

requires true
func closureSpec3(c BatchConn)
/** End of closure specs for the Run method **/

/** Start of io-spec helper functions **/

ghost 
requires seg1Len > 0
requires seg2Len >= 0
requires seg3Len >= 0
requires currHF < seg1Len + seg2Len + seg3Len
decreases
pure func computeSeqLen(currHF int, seg1Len int, seg2Len int, seg3Len int) int{
	return seg1Len > currHF ? seg1Len : ((seg1Len + seg2Len) > currHF ? seg2Len : seg3Len)
}

ghost 
decreases
pure func infoFieldOffsetSeg(currINF int) int{
	return 4 + 8 * currINF
}

ghost 
decreases 
pure func numInfoFields(seg1Len int, seg2Len int, seg3Len int) int {
	return seg3Len > 0 ? 3 : (seg2Len > 0 ? 2 : 1)
}

ghost 
requires seg1Len > 0
requires seg2Len >= 0
requires seg3Len >= 0
requires currHF >= 0
ensures  res <= currHF
decreases
pure func computePrevSegLen(currHF int, seg1Len int, seg2Len int, seg3Len int) (res int){
	return seg1Len > currHF ? 0 : ((seg1Len + seg2Len) > currHF ? seg1Len : seg1Len + seg2Len)
}

//expects the raw bytes of whole path
ghost
requires start + 12 <= len(raw)
requires 0 <= start
requires acc(&raw[start+2], _) && acc(&raw[start+3], _) && acc(&raw[start+4], _) && acc(&raw[start+5], _)
decreases
pure func getHopField(raw []byte, start int) io.IO_HF {
	return let inif2 := binary.BigEndian.Uint16(raw[start+2:start+4]) in
		let egif2 := binary.BigEndian.Uint16(raw[start+4:start+6]) in
		io.IO_HF(io.IO_HF_{
			InIF2 : inif2 == 0 ? none[io.IO_ifs] : some(io.IO_ifs(inif2)),
			EgIF2 : egif2 == 0 ? none[io.IO_ifs] : some(io.IO_ifs(egif2)),
			HVF : computeMsgTerm(raw, start),
		})
}

ghost
requires idx + 12 <= len(raw)
requires 0 <= idx
requires acc(&raw[idx+2], _) && acc(&raw[idx+3], _) && acc(&raw[idx+4], _) && acc(&raw[idx+5], _)
ensures  len(res.HVF.MsgTerm_Hash_.MsgTerm_MPair_2.MsgTerm_L_) > 0
decreases
pure func getHopField2(raw []byte, idx int, beta set[io.IO_msgterm], asid io.IO_as, ainfo io.IO_ainfo) (res io.IO_HF) {
	return let inif2 := binary.BigEndian.Uint16(raw[idx+2:idx+4]) in
		let egif2 := binary.BigEndian.Uint16(raw[idx+4:idx+6]) in
		let op_inif2 := inif2 == 0 ? none[io.IO_ifs] : some(io.IO_ifs(inif2)) in
		let op_egif2 := egif2 == 0 ? none[io.IO_ifs] : some(io.IO_ifs(egif2)) in
		let ts := io.IO_msgterm(io.MsgTerm_Num{ainfo}) in
		let l := io.IO_msgterm(io.MsgTerm_L{seq[io.IO_msgterm]{ts, io.if2term(op_inif2), io.if2term(op_egif2), 
			io.IO_msgterm(io.MsgTerm_FS{beta})}}) in
		let hvf := io.mac(io.macKey(io.asidToKey(asid)), l) in
		io.IO_HF(io.IO_HF_{
			InIF2 : op_inif2,
			EgIF2 : op_egif2,
			HVF : hvf,
		})
}

ghost 
requires  0 <= offset
requires  0 <= currHFIdx && currHFIdx <= segLen
requires  offset + 12 * segLen <= len(raw)
requires  acc(sl.AbsSlice_Bytes(raw, 0, len(raw)), _)
ensures   len(res) == segLen - currHFIdx
ensures   forall k int :: 0 <= k && k < len(res) ==> 
	len(res[k].HVF.MsgTerm_Hash_.MsgTerm_MPair_2.MsgTerm_L_) > 0
decreases segLen - currHFIdx
pure func getHopfieldsConsDir(raw []byte, offset int, currHFIdx int, segLen int, beta set[io.IO_msgterm], asid io.IO_as, ainfo io.IO_ainfo) (res seq[io.IO_HF]){
	return currHFIdx == segLen ? seq[io.IO_HF]{} : 
		let hf := (unfolding acc(sl.AbsSlice_Bytes(raw, 0, len(raw)), _) in getHopField2(raw, offset + 12 * currHFIdx, beta, asid, ainfo)) in
		seq[io.IO_HF]{hf} ++ getHopfieldsConsDir(raw, offset, currHFIdx + 1, segLen, (beta union set[io.IO_msgterm]{hf.HVF}), asid, ainfo)
}

ghost 
requires  0 <= offset 
requires  -1 <= currHFIdx
requires  offset + 12 * currHFIdx + 12 <= len(raw)
requires  acc(sl.AbsSlice_Bytes(raw, 0, len(raw)), _)
ensures   len(res) == currHFIdx + 1
ensures   forall k int :: 0 <= k && k < len(res) ==> 
	len(res[k].HVF.MsgTerm_Hash_.MsgTerm_MPair_2.MsgTerm_L_) > 0
decreases currHFIdx + 1
pure func getHopfieldsNotConsDir(raw []byte, offset int, currHFIdx int, beta set[io.IO_msgterm], asid io.IO_as, ainfo io.IO_ainfo) (res seq[io.IO_HF]){
	return currHFIdx == -1 ? seq[io.IO_HF]{} : 
		let hf := (unfolding acc(sl.AbsSlice_Bytes(raw, 0, len(raw)), _) in getHopField2(raw, offset + 12 * currHFIdx, beta, asid, ainfo)) in
		getHopfieldsNotConsDir(raw, offset, currHFIdx -1, (beta union set[io.IO_msgterm]{hf.HVF}), asid, ainfo) ++ seq[io.IO_HF]{hf}
}

ghost 
requires -1 <= currHFIdx && currHFIdx < len(hopfields)
decreases currHFIdx + 1
pure func getSegPast2(hopfields seq[io.IO_HF], currHFIdx int) seq[io.IO_HF]{
	return currHFIdx == -1  ? seq[io.IO_HF]{} : 
		seq[io.IO_HF]{hopfields[currHFIdx]} ++ getSegPast2(hopfields, currHFIdx - 1)
}

//expects the raw bytes of whole path
ghost 
requires 4 + 8 * numINF + offset * 12 + 12 <= len(raw)
requires prevSegLen >= 0 && offset - prevSegLen >= -1
requires 0 < numINF && numINF < 4
requires acc(sl.AbsSlice_Bytes(raw, 0, len(raw)), _)
decreases offset - prevSegLen + 1
pure func getSegPast(raw []byte, prevSegLen int, offset int, numINF int) seq[io.IO_HF]{
	return offset - prevSegLen == -1 ? seq[io.IO_HF]{} : 
		(unfolding acc(sl.AbsSlice_Bytes(raw, 0, len(raw)), _) in 
			seq[io.IO_HF]{getHopField(raw,4 + 8 * numINF + offset*12)}) ++ getSegPast(raw, prevSegLen, offset-1, numINF)
}

ghost 
requires 0 <= currHFIdx && currHFIdx <= len(hopfields)
decreases len(hopfields) - currHFIdx
pure func getSegFuture2(hopfields seq[io.IO_HF], currHFIdx int) seq[io.IO_HF]{
	return currHFIdx == len(hopfields) ? seq[io.IO_HF]{} : 
		seq[io.IO_HF]{hopfields[currHFIdx]} ++ getSegFuture2(hopfields, currHFIdx + 1)
}

//expects the raw bytes of whole path
ghost 
requires 4 + 8 * numINF + offset*12 + 12 <= len(raw)
requires offset >= currHF && currHF >= 0
requires 0 < numINF && numINF < 4
requires acc(sl.AbsSlice_Bytes(raw, 0, len(raw)), _)
decreases offset - currHF
pure func getSegFuture(raw []byte, currHF int, offset int, numINF int) seq[io.IO_HF]{
	return offset == currHF ? (unfolding acc(sl.AbsSlice_Bytes(raw, 0, len(raw)), _) in seq[io.IO_HF]{getHopField(raw,4 + 8 * numINF + offset*12)}) : 
		getSegFuture(raw, currHF, offset-1, numINF) ++ (unfolding acc(sl.AbsSlice_Bytes(raw, 0, len(raw)), _) in seq[io.IO_HF]{getHopField(raw, 4 + 8 * numINF + offset*12)})
}

ghost 
requires -1 <= currHFIdx && currHFIdx < len(hopfields)
decreases currHFIdx + 1
pure func getSegHistory2(hopfields seq[io.IO_HF], currHFIdx int) seq[io.IO_ahi]{
	return currHFIdx == -1 ? seq[io.IO_ahi]{} : 
		seq[io.IO_ahi]{hopfields[currHFIdx].Toab()} ++ getSegHistory2(hopfields, currHFIdx - 1)
			
}

//expects the raw bytes of whole path
ghost 
requires 4 + 8 * numINF + offset*12 + 12 <= len(raw)
requires prevSegLen >= 0 && offset - prevSegLen >= -1
requires 0 < numINF && numINF < 4
requires acc(sl.AbsSlice_Bytes(raw, 0, len(raw)), _)
decreases offset - prevSegLen + 1
pure func getSegHistory(raw []byte, prevSegLen int, offset int, numINF int) seq[io.IO_ahi]{
	return offset - prevSegLen == -1 ? seq[io.IO_ahi]{} : 
		(unfolding acc(sl.AbsSlice_Bytes(raw, 0, len(raw)), _) in 
			seq[io.IO_ahi]{getHopField(raw,4 + 8 * numINF + offset*12).Toab()}) ++ getSegHistory(raw, prevSegLen, offset-1, numINF)
}

ghost
requires len(hopfield.HVF.MsgTerm_Hash_.MsgTerm_MPair_2.MsgTerm_L_) > 0
decreases
pure func getHVFSet(hopfield io.IO_HF) set[io.IO_msgterm]{
	return let l := hopfield.HVF.MsgTerm_Hash_.MsgTerm_MPair_2.MsgTerm_L_ in
		l[len(l) - 1].MsgTerm_FS_
}

ghost
requires 0 < len(hopfields)
requires 0 <= currHFIdx && currHFIdx <= len(hopfields)
requires forall idx int :: 0 <= idx && idx < len(hopfields) ==>
	len(hopfields[idx].HVF.MsgTerm_Hash_.MsgTerm_MPair_2.MsgTerm_L_) > 0
decreases
pure func getUInfo(hopfields seq[io.IO_HF], currHFIdx int, consDir bool) set[io.IO_msgterm]{
	return currHFIdx == len(hopfields) ? getHVFSet(hopfields[currHFIdx-1]) :
		currHFIdx == 0 ? getHVFSet(hopfields[currHFIdx]) :
		consDir ? getHVFSet(hopfields[currHFIdx]) : getHVFSet(hopfields[currHFIdx-1]) 
}

ghost 
requires 0 <= offset
requires 0 < segLen
requires offset + 12 * segLen <= len(raw)
requires 0 <= currHFIdx && currHFIdx <= segLen
requires acc(sl.AbsSlice_Bytes(raw, 0, len(raw)), _)
decreases 
pure func getSegment2(raw []byte, offset int, currHFIdx int, segLen int, asid io.IO_as, ainfo io.IO_ainfo, consDir bool, peer bool) io.IO_seg2{
	return let hopfields := consDir ?
		getHopfieldsConsDir(raw, offset, 0, segLen, set[io.IO_msgterm]{}, asid, ainfo) : 
		getHopfieldsNotConsDir(raw, offset, segLen - 1, set[io.IO_msgterm]{}, asid, ainfo) in
		let uinfo := getUInfo(hopfields, currHFIdx, consDir) in
		io.IO_seg2(io.IO_seg3_{
			AInfo :ainfo,
			UInfo : uinfo,
			ConsDir : consDir,
			Peer : peer,
			Past : getSegPast2(hopfields, currHFIdx - 1),
			Future : getSegFuture2(hopfields, currHFIdx),
			History : getSegHistory2(hopfields, currHFIdx - 1),
		})
}

//expects the raw bytes of whole path
ghost 
requires 4 + 8 * numINF + 12 * (prevSegLen + segLen) <= len(raw)
requires prevSegLen >= 0 && segLen >= 0
requires 0 < numINF && numINF < 4
requires segLen+prevSegLen > currHF && currHF >= prevSegLen
requires acc(sl.AbsSlice_Bytes(raw, 0, len(raw)), _)
decreases 
pure func getSegment(raw []byte, consDir bool, peer bool, currHF int, prevSegLen int, segLen int, numINF int, currINF int) io.IO_seg2{
	return io.IO_seg2(io.IO_seg3_{
		AInfo : computeAInfo(raw, currINF),
		UInfo : computeUInfo(raw, currINF),
		ConsDir : consDir,
		Peer : peer,
		Past : getSegPast(raw, prevSegLen, currHF - 1, numINF),
		Future : getSegFuture(raw, currHF, segLen+prevSegLen-1, numINF),
		History : getSegHistory(raw, prevSegLen, currHF - 1, numINF),
	})
}

//expects the raw bytes of whole path
ghost
requires 4 + 8 * numINF + 12 * (prevSegLen + segLen) <= len(raw)
requires prevSegLen >= 0 && segLen >= 0
requires 0 < numINF && numINF < 4
requires segLen+prevSegLen > currHF && currHF >= prevSegLen
requires acc(sl.AbsSlice_Bytes(raw, 0, len(raw)), _)
decreases 
pure func getPastSegment(raw []byte, consDir bool, peer bool, currHF int, prevSegLen int, segLen int, numINF int, currINF int) io.IO_seg2{
	return io.IO_seg2(io.IO_seg3_{
		AInfo : computeAInfo(raw, currINF),
		UInfo : computeUInfo(raw, currINF),
		ConsDir : consDir,
		Peer : peer,
		Past : getSegPast(raw, prevSegLen, currHF, numINF),
		Future : seq[io.IO_HF]{},
		History : getSegHistory(raw, prevSegLen, currHF, numINF),
	})
}

ghost
requires 4 + 8 * currINFIdx + 8 <= offset
requires 0 < segLen
requires offset + 12 * segLen <= len(raw)
requires 0 <= currHFIdx && currHFIdx <= segLen
requires 0 <= currINFIdx && currINFIdx < 3
requires acc(sl.AbsSlice_Bytes(raw, 0, len(raw)), _)
decreases 
pure func getCurrSeg2(raw []byte, offset int, currINFIdx int, currHFIdx int, segLen int, asid io.IO_as) io.IO_seg3 {
	return unfolding acc(sl.AbsSlice_Bytes(raw, 0, len(raw)), _) in
		let ainfo := getTimestamp(raw, currINFIdx) in
		let consDir := getConsDir(raw, currINFIdx) in
		let peer := getPeer(raw, currINFIdx) in
		getSegment2(raw, offset, currHFIdx, segLen, asid, ainfo, consDir, peer)
}

ghost
requires seg1Len > 0
requires seg2Len >= 0
requires seg3Len >= 0
requires 4 + 8 * numInfoFields(seg1Len, seg2Len, seg3Len) + 12 * (seg1Len + seg2Len + seg3Len) == len(raw)
requires 0 <= currINF && currINF < 3
requires 0 <= currHF && currHF < seg1Len + seg2Len + seg3Len
requires computeSeqLen(currHF, seg1Len, seg2Len, seg3Len) + computePrevSegLen(currHF, seg1Len, seg2Len, seg3Len) > currHF
requires acc(sl.AbsSlice_Bytes(raw, 0, len(raw)), _)
decreases 
pure func getCurrSeg(raw []byte, currINF int, currHF int, seg1Len int, seg2Len int, seg3Len int) io.IO_seg3 {
	return let consDir := getConsDir(raw, currINF) in
		let peer := getPeer(raw, currINF) in
		let segLen := computeSeqLen(currHF, seg1Len, seg2Len, seg3Len) in
		let prevSegLen := computePrevSegLen(currHF, seg1Len, seg2Len, seg3Len) in
		let numINF := numInfoFields(seg1Len, seg2Len, seg3Len) in
		getSegment(raw, consDir, peer, currHF, prevSegLen, segLen, numINF, currINF)
}

ghost
requires 0 < seg1Len
requires 0 <= seg2Len
requires 0 <= seg3Len
requires 4 + 8 * numInfoFields(seg1Len, seg2Len, seg3Len) == offset
requires offset + 12 * (seg1Len + seg2Len + seg3Len) <= len(raw)
requires 1 <= currINFIdx && currINFIdx < 4
requires acc(sl.AbsSlice_Bytes(raw, 0, len(raw)), _)
decreases 
pure func getLeftSeg2(raw []byte, offset int, currINFIdx int, seg1Len int, seg2Len int, seg3Len int, asid io.IO_as) option[io.IO_seg3] {
	return (currINFIdx == 1 && seg2Len > 0) ? some(getCurrSeg2(raw, offset + 12 * seg1Len, currINFIdx, 0, seg2Len, asid)) : 
		(currINFIdx == 2 && seg3Len > 0) ? some(getCurrSeg2(raw, offset + 12 * (seg1Len + seg2Len), currINFIdx, 0, seg3Len, asid)) : none[io.IO_seg3]
}

ghost
requires seg1Len > 0
requires seg2Len >= 0
requires seg3Len >= 0
requires 4 + 8 * numInfoFields(seg1Len, seg2Len, seg3Len) + 12 * (seg1Len + seg2Len + seg3Len) == len(raw)
requires 0 <= currINF && currINF < 3
requires 0 <= currHF && currHF < seg1Len + seg2Len + seg3Len
requires computeSeqLen(currHF, seg1Len, seg2Len, seg3Len) + computePrevSegLen(currHF, seg1Len, seg2Len, seg3Len) > currHF
requires acc(sl.AbsSlice_Bytes(raw, 0, len(raw)), _)
decreases 
pure func getLeftSeg(raw []byte, currINF int, currHF int, seg1Len int, seg2Len int, seg3Len int) option[io.IO_seg3] {
	return let newCurrHF := computeSeqLen(currHF, seg1Len, seg2Len, seg3Len) + computePrevSegLen(currHF, seg1Len, seg2Len, seg3Len) in
		(newCurrHF == seg1Len + seg2Len + seg3Len || currINF == 2) ? none[io.IO_seg3] :
			some(getCurrSeg(raw, currINF + 1, newCurrHF, seg1Len, seg2Len, seg3Len))
}

ghost
requires 0 < seg1Len
requires 0 <= seg2Len
requires 0 <= seg3Len
requires 4 + 8 * numInfoFields(seg1Len, seg2Len, seg3Len) == offset
requires offset + 12 * (seg1Len + seg2Len + seg3Len) <= len(raw)
requires -1 <= currINFIdx && currINFIdx < 2
requires acc(sl.AbsSlice_Bytes(raw, 0, len(raw)), _)
decreases
pure func getRightSeg2(raw []byte, offset int, currINFIdx int, seg1Len int, seg2Len int, seg3Len int, asid io.IO_as) option[io.IO_seg3] {
	return (currINFIdx == 1 && seg3Len > 0 && seg2Len > 0) ? some(getCurrSeg2(raw, offset + 12 * seg1Len, currINFIdx, seg2Len, seg2Len, asid)) :
		(currINFIdx == 0 && seg2Len > 0) ? some(getCurrSeg2(raw, offset, currINFIdx, seg1Len, seg1Len, asid)) : none[io.IO_seg3]					
}

ghost
requires seg1Len > 0
requires seg2Len >= 0
requires seg3Len >= 0
requires 4 + 8 * numInfoFields(seg1Len, seg2Len, seg3Len) + 12 * (seg1Len + seg2Len + seg3Len) == len(raw)
requires 0 <= currINF && currINF < 3
requires 0 <= currHF && currHF < seg1Len + seg2Len + seg3Len
requires computeSeqLen(currHF, seg1Len, seg2Len, seg3Len) + computePrevSegLen(currHF, seg1Len, seg2Len, seg3Len) > currHF
requires acc(sl.AbsSlice_Bytes(raw, 0, len(raw)), _)
decreases 
pure func getRightSeg(raw []byte, currINF int, currHF int, seg1Len int, seg2Len int, seg3Len int) option[io.IO_seg3] {
	return (computePrevSegLen(currHF, seg1Len, seg2Len, seg3Len) == 0 || currINF == 0) ? none[io.IO_seg3] :
		(let newCurrHF := computePrevSegLen(currHF, seg1Len, seg2Len, seg3Len)-1 in
		let consDir := getConsDir(raw, currINF-1) in
		let peer := getPeer(raw, currINF-1) in
		let segLen := computeSeqLen(newCurrHF, seg1Len, seg2Len, seg3Len) in
		let prevSegLen := computePrevSegLen(newCurrHF, seg1Len, seg2Len, seg3Len) in
		let numINF := numInfoFields(seg1Len, seg2Len, seg3Len) in
		some(getPastSegment(raw, consDir, peer, newCurrHF, prevSegLen, segLen, numINF, currINF)))
}

ghost
requires 0 < seg1Len
requires 0 <= seg2Len
requires 0 <= seg3Len
requires 4 + 8 * numInfoFields(seg1Len, seg2Len, seg3Len) == offset
requires offset + 12 * (seg1Len + seg2Len + seg3Len) <= len(raw)
requires 2 <= currINFIdx && currINFIdx < 5
requires acc(sl.AbsSlice_Bytes(raw, 0, len(raw)), _)
decreases 
pure func getMidSeg2(raw []byte, offset int, currINFIdx int, seg1Len int, seg2Len int, seg3Len int, asid io.IO_as) option[io.IO_seg3] {
	return (currINFIdx == 4 && seg3Len > 0) ? some(getCurrSeg2(raw, offset, 0, seg1Len, seg1Len, asid)) :
		(currINFIdx == 2 && seg3Len > 0) ? some(getCurrSeg2(raw, offset + 12 * (seg1Len + seg2Len), currINFIdx, 0, seg3Len, asid)) : none[io.IO_seg3]
}

ghost
requires seg1Len > 0
requires seg2Len >= 0
requires seg3Len >= 0
requires 4 + 8 * numInfoFields(seg1Len, seg2Len, seg3Len) + 12 * (seg1Len + seg2Len + seg3Len) == len(raw)
requires 0 <= currINF && currINF < 3
requires 0 <= currHF && currHF < seg1Len + seg2Len + seg3Len
requires computeSeqLen(currHF, seg1Len, seg2Len, seg3Len) + computePrevSegLen(currHF, seg1Len, seg2Len, seg3Len) > currHF
requires acc(sl.AbsSlice_Bytes(raw, 0, len(raw)), _)
decreases 
pure func getMidSeg(raw []byte, currINF int, currHF int, seg1Len int, seg2Len int, seg3Len int) option[io.IO_seg3] {
	return seg3Len == 0 ? none[io.IO_seg3] :
		(computePrevSegLen(currHF, seg1Len, seg2Len, seg3Len) == seg1Len) ? none[io.IO_seg3] :
			(computePrevSegLen(currHF, seg1Len, seg2Len, seg3Len) == 0) ? some(getCurrSeg(raw, 2, seg1Len + seg2Len, seg1Len, seg2Len, seg3Len)) : 
				(let consDir := getConsDir(raw, 0) in
				let peer := getPeer(raw, 0) in
				let numINF := numInfoFields(seg1Len, seg2Len, seg3Len) in
				some(getPastSegment(raw, consDir, peer, seg1Len-1, 0, seg1Len, numINF, currINF)))
}

ghost 
requires len(raw) > 4
requires acc(sl.AbsSlice_Bytes(raw, 0, len(raw)), _)
requires unfolding acc(sl.AbsSlice_Bytes(raw, 0, len(raw)), _) in 
	let hdr := binary.BigEndian.Uint32(raw[0:4]) in
	0 <= getCurrINF(hdr) && getCurrINF(hdr) < 3 &&
	getCurrINF(hdr) + 1 <= numInfoFields(int(getSeg1Len(hdr)), int(getSeg2Len(hdr)), int(getSeg3Len(hdr))) &&
	0 <= getCurrHF(hdr) && getCurrHF(hdr) < getSeg1Len(hdr) + getSeg2Len(hdr) + getSeg3Len(hdr) &&
	0 < getSeg1Len(hdr) &&
	0 <= getSeg2Len(hdr) && 
	0 <= getSeg3Len(hdr) &&
	4 + 8 * numInfoFields(int(getSeg1Len(hdr)), int(getSeg2Len(hdr)), int(getSeg3Len(hdr))) + 12 * (int(getSeg1Len(hdr)) + int(getSeg2Len(hdr)) + int(getSeg3Len(hdr))) == len(raw)
decreases 
pure func getPkt2(raw []byte, asid io.IO_as) io.IO_pkt2{
	return let hdr := unfolding acc(sl.AbsSlice_Bytes(raw, 0, len(raw)), _) in binary.BigEndian.Uint32(raw[0:4]) in
		let currINFIdx := int(getCurrINF(hdr)) in
		let currHFIdx := int(getCurrHF(hdr)) in
		let seg1Len := int(getSeg1Len(hdr)) in
		let seg2Len := int(getSeg2Len(hdr)) in 
		let seg3Len := int(getSeg3Len(hdr)) in
		let segLen := computeSeqLen(currHFIdx, seg1Len, seg2Len, seg3Len) in
		let prevSegLen := computePrevSegLen(currHFIdx, seg1Len, seg2Len, seg3Len) in
		let numINF := int(numInfoFields(seg1Len, seg2Len, seg3Len)) in
		let offset := 4 + 8 * numINF in
		io.IO_pkt2(io.IO_Packet2{
			CurrSeg : getCurrSeg2(raw, offset+prevSegLen, currINFIdx, currHFIdx-prevSegLen, segLen, asid), // currINFIdx = {0, 1, 2}
			LeftSeg : getLeftSeg2(raw, offset, currINFIdx + 1, seg1Len, seg2Len , seg3Len, asid), //  currINFIdx = {1, 2, 3}
			MidSeg : getMidSeg2(raw, offset, currINFIdx + 2, seg1Len, seg2Len , seg3Len, asid), //  currINFIdx = {2, 3, 4}
			RightSeg : getRightSeg2(raw, offset, currINFIdx - 1, seg1Len, seg2Len , seg3Len, asid), //  currINFIdx = {-1, 0, 1}
		})
}

//TODO improve preconditions
ghost 
requires len(raw) > 4
requires acc(sl.AbsSlice_Bytes(raw, 0, len(raw)), _)
requires unfolding acc(sl.AbsSlice_Bytes(raw, 0, len(raw)), _) in 
	let hdr := binary.BigEndian.Uint32(raw[0:4]) in
	0 <= getCurrINF(hdr) && getCurrINF(hdr) < 3 &&
	0 <= getCurrHF(hdr) && getCurrHF(hdr) < getSeg1Len(hdr) + getSeg2Len(hdr) + getSeg3Len(hdr) &&
	0 < getSeg1Len(hdr) &&
	0 <= getSeg2Len(hdr) && 
	0 <= getSeg3Len(hdr) &&
	4 + 8 * numInfoFields(int(getSeg1Len(hdr)), int(getSeg2Len(hdr)), int(getSeg3Len(hdr))) + 12 * (int(getSeg1Len(hdr)) + int(getSeg2Len(hdr)) + int(getSeg3Len(hdr))) == len(raw)
decreases 
pure func getPkt(raw []byte) io.IO_pkt2{
	return let hdr := unfolding acc(sl.AbsSlice_Bytes(raw, 0, len(raw)), _) in binary.BigEndian.Uint32(raw[0:4]) in
		let currINF := getCurrINF(hdr) in
		let currHF := getCurrHF(hdr) in
		let seg1Len := getSeg1Len(hdr) in
		let seg2Len := getSeg2Len(hdr) in 
		let seg3Len := getSeg3Len(hdr) in
		io.IO_pkt2(io.IO_Packet2{
			CurrSeg : getCurrSeg(raw, int(currINF), int(currHF), int(seg1Len), int(seg2Len), int(seg3Len)),
			LeftSeg : getLeftSeg(raw, int(currINF), int(currHF), int(seg1Len), int(seg2Len), int(seg3Len)),
			MidSeg : getMidSeg(raw, int(currINF), int(currHF), int(seg1Len), int(seg2Len), int(seg3Len)),
			RightSeg : getRightSeg(raw, int(currINF), int(currHF), int(seg1Len), int(seg2Len), int(seg3Len)),
		})
}

ghost
decreases
pure func getCurrINF(hdr uint32) uint8{
	return uint8(hdr >> 30)
}

ghost
decreases
pure func getCurrHF(hdr uint32) uint8{
	return uint8(hdr >> 24) & 0x3F
}

ghost
decreases
pure func getSeg1Len(hdr uint32) uint8{
	return uint8(hdr >> 12) & 0x3F
}

ghost
decreases
pure func getSeg2Len(hdr uint32) uint8{
	return uint8(hdr >> 6) & 0x3F
}

ghost
decreases
pure func getSeg3Len(hdr uint32) uint8{
	return uint8(hdr) & 0x3F
}

ghost 
requires 0 <= offset
requires infoFieldOffsetSeg(offset) < len(raw)
requires acc(&raw[infoFieldOffsetSeg(offset)], _)
decreases
pure func getConsDir(raw []byte, offset int) bool{
	return raw[infoFieldOffsetSeg(offset)] & 0x1 == 0x1
}

ghost 
requires 0 <= offset
requires infoFieldOffsetSeg(offset) < len(raw)
requires acc(&raw[infoFieldOffsetSeg(offset)], _)
decreases
pure func getPeer(raw []byte, offset int) bool{
	return raw[infoFieldOffsetSeg(offset)] & 0x2 == 0x2
}

ghost 
requires 0 <= offset
requires infoFieldOffsetSeg(offset) + 8 < len(raw)
requires acc(&raw[infoFieldOffsetSeg(offset) + 4], _)
requires acc(&raw[infoFieldOffsetSeg(offset) + 5], _)
requires acc(&raw[infoFieldOffsetSeg(offset) + 6], _)
requires acc(&raw[infoFieldOffsetSeg(offset) + 7], _)
decreases
pure func getTimestamp(raw []byte, offset int) io.IO_ainfo{
	return let idx := infoFieldOffsetSeg(offset) + 4 in 
		io.IO_ainfo(binary.BigEndian.Uint32(raw[idx : idx + 4]))
}

// TODO Do we need a body?
ghost
decreases
pure func computeMsgTerm(raw []byte, start int) io.IO_msgterm

ghost
decreases
pure func computeAInfo(raw []byte, currINF int) io.IO_ainfo

ghost 
decreases
pure func computeUInfo(raw []byte, currINF int) set[io.IO_msgterm]

/** End of io-spec helper functions **/ 