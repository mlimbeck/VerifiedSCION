// Copyright 2022 ETH Zurich
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//   http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// +gobra

package router

import (
	"sync"
	io "github.com/scionproto/scion/verification/io"
  sl "github.com/scionproto/scion/verification/utils/slices"
)

ghost
decreases
ensures ElemWitness(y, k, e)
func AssumeElemWitness(ghost y ElemRA, ghost k Key, ghost e Elem)

type Pkt []byte
//pred PktMem(Pkt)

ghost
decreases
requires acc(sl.AbsSlice_Bytes(p, 0, len(p)), _)
ensures e.isIO_val_Pkt2 || e.isIO_val_Unsupported
pure func IO_val_Abs(p Pkt) (ghost e io.IO_val) {

}

decreases 
requires Prophecy(prophecyM)
requires io.token(t) && MultiReadBio(t, prophecyM)
requires forall i int :: {&buf[i]} 0 <= i && i < len(buf) ==> acc(&buf[i])
ensures  prophecyM == m
ensures  0 <= m && m <= len(buf) 
ensures  io.token(old(MutliReadBio_next(t, m, m))) && old(MutliReadBio_correctIfs(t, m, m, IfsToIO_ifs(c)))
ensures  forall i int :: {&buf[i]} 0 <= i && i < len(buf) ==> acc(&buf[i])
ensures  forall i int :: {buf[i]} 0 <= i && i < m ==> acc(sl.AbsSlice_Bytes(buf[i], 0, len(buf[i])), _) && IO_val_Abs(buf[i]) == old(MutliReadBio_IO_val(t, m, m)[i])
func BatchRecv(c uint16, buf []Pkt, ghost prophecyM int, ghost t io.Place) (m int)

//----------------------------------------------------------------------//

requires dp.Valid()
requires io.token(p) && dp.dp3s_iospec_ordered(s, p)
func rc (ingressID uint16, ghost p io.Place, ghost s io.IO_dp3s_state_local, ghost dp io.DataPlaneSpec) {
  ghost m, y := InitSharedInv(dp, p, s)
  ghost from := IfsToIO_ifs(ingressID)
  buf := make([]Pkt, 1000)

  invariant acc(m.LockP(), _) && m.LockInv() == SharedInv!< dp, y !>;
  invariant forall i int :: {&buf[i]} 0 <= i && i < len(buf) ==> acc(&buf[i])
  for true {
    ghost n := len(buf)
    // multi recv
    ghost m.Lock()
    unfold SharedInv!< dp, y !>()

    ghost t, s := *y.Place, *y.State
    ghost numberOfReceivedPacketsProphecy := AllocProphecy() 
    ExtractMultiReadBio(dp, t, numberOfReceivedPacketsProphecy, s)
    MultiUpdateElemWitness2(t, numberOfReceivedPacketsProphecy, numberOfReceivedPacketsProphecy, from, s, y)
    ghost es_val := MutliReadBio_IO_val(t,numberOfReceivedPacketsProphecy, numberOfReceivedPacketsProphecy)

    ghost sN := MultiReadBio_Upd(t, numberOfReceivedPacketsProphecy, numberOfReceivedPacketsProphecy, s)
    ghost tN := MutliReadBio_next(t, numberOfReceivedPacketsProphecy, numberOfReceivedPacketsProphecy)
    assert dp.dp3s_iospec_ordered(sN, tN)
    pkts := BatchRecv(ingressID, buf, numberOfReceivedPacketsProphecy, t)
    
    MultiElemWitnessConv(y.IBufY, from, es_val)
    //assert forall i int :: {es_val[i]} 0 <= i && i < pkts ==> PktMem(buf[i]) && IO_val_Abs(buf[i]) == es_val[i]
    //assert MultiElemWitness0(y.IBufY, from, es_val, 0)

    ghost *y.State = sN
    ghost *y.Place = tN

    fold SharedInv!< dp, y !>()
    m.Unlock()
    //end of recv
    
    if pkts == 0{
        continue
    }
    ghost k := 0

    invariant IfsToIO_ifs(ingressID) == from
    invariant acc(m.LockP(), _) && m.LockInv() == SharedInv!< dp, y !>;
    invariant forall i int :: {&buf[i]} 0 <= i && i < len(buf) ==> acc(&buf[i])
    invariant forall i int :: {buf[i]} k <= i && i < pkts ==> acc(sl.AbsSlice_Bytes(buf[i], 0, len(buf[i])), _) && IO_val_Abs(buf[i]) == es_val[i]
    invariant MultiElemWitness0(y.IBufY, from, es_val, k)
    for _, p := range buf[:pkts] with k {
      unfold MultiElemWitness0(y.IBufY, from, es_val, k)
      //assume IO_val_Abs(p).isIO_val_Pkt2
      ghost newPkt := processPkt(p, ingressID, m, y, dp)
      assume newPkt.isIO_val_Pkt2

      //send
      ghost m.Lock()
      unfold SharedInv!< dp, y !>()

      t, s := *y.Place, *y.State

      ApplyElemWitness(s.obuf, y.OBufY, newPkt.IO_val_Pkt2_1, newPkt.IO_val_Pkt2_2)
      assert newPkt.IO_val_Pkt2_2 in AsSet(s.obuf[newPkt.IO_val_Pkt2_1])
      
      assert dp.dp3s_iospec_bio3s_send_guard(s, t, newPkt)

      unfold dp.dp3s_iospec_ordered(s, t)
      unfold dp.dp3s_iospec_bio3s_send(s, t)

      tN := io.dp3s_iospec_bio3s_send_T(t, newPkt)
      io.Send(t, newPkt)
      
      ghost *y.Place = tN
      
      fold SharedInv!< dp, y !>()
      ghost m.Unlock()
    }
  }
}

requires dp.Valid()
requires acc(sl.AbsSlice_Bytes(p, 0, len(p)), _)
requires acc(m.LockP(), _) && m.LockInv() == SharedInv!< dp, y !>;
requires IO_val_Abs(p).isIO_val_Pkt2 ==> ElemWitness(y.IBufY, IfsToIO_ifs(ingressID), IO_val_Abs(p).IO_val_Pkt2_2)
ensures acc(sl.AbsSlice_Bytes(p, 0, len(p)), _)
ensures newPkt.isIO_val_Pkt2 ==> ElemWitness(y.OBufY, newPkt.IO_val_Pkt2_1, newPkt.IO_val_Pkt2_2)
func processPkt(p Pkt, ghost ingressID uint16, ghost m *sync.Mutex, ghost y SharedArg, ghost dp io.DataPlaneSpec) (ghost newPkt io.IO_val) {
  var pathType int
  assume IO_val_Abs(p).isIO_val_Pkt2 ==> pathType == 1
  assume pathType == 1 ==> IO_val_Abs(p).isIO_val_Pkt2
  if pathType == 1 {
    //assume IfsToIO_ifs(ingressID) == IO_val_Abs(p).IO_val_Pkt2_1
    //Process(p, ingressID, m, y)
    assume newPkt.isIO_val_Pkt2
    AssumeElemWitness(y.OBufY, newPkt.IO_val_Pkt2_1, newPkt.IO_val_Pkt2_2)
  } else {
    assume !newPkt.isIO_val_Pkt2
  }
  return newPkt
}


requires dp.Valid()
requires acc(sl.AbsSlice_Bytes(p, 0, len(p)), _)
requires acc(m.LockP(), _) && m.LockInv() == SharedInv!< dp, y !>;
requires IO_val_Abs(p).isIO_val_Pkt2
requires ElemWitness(y.IBufY, IfsToIO_ifs(ingressID), IO_val_Abs(p).IO_val_Pkt2_2)
requires IO_val_Abs(p).IO_val_Pkt2_1 == IfsToIO_ifs(ingressID)
func Process(p Pkt, ghost ingressID uint16, ghost m *sync.Mutex, ghost y SharedArg, ghost dp io.DataPlaneSpec) (ghost newPkt io.IO_val){
  ghost pkt := IO_val_Abs(p)
  //Inbound
  //enter
  ghost if IO_val_Abs(p).IO_val_Pkt2_1 != none[io.IO_ifs] { 
    assume false
  } else { //exit
    ghost m.Lock()
    unfold SharedInv!< dp, y !>()
    t, s := *y.Place, *y.State

    ApplyElemWitness(s.ibuf, y.IBufY, IfsToIO_ifs(ingressID), pkt.IO_val_Pkt2_2)
	  assert pkt.IO_val_Pkt2_2 in AsSet(s.ibuf[IfsToIO_ifs(ingressID)])
    
    
    unfold dp.dp3s_iospec_ordered(s, t)
	  unfold dp.dp3s_iospec_bio3s_exit(s, t)
    assert pkt.IO_val_Pkt2_1 in domain(s.ibuf)
    assert let ibuf_set := s.ibuf[pkt.IO_val_Pkt2_1] in (pkt.IO_val_Pkt2_2 in ibuf_set)
    assume len(pkt.IO_val_Pkt2_2.CurrSeg.Future) > 0 

		// dp.dp3s_forward_ext(v.IO_Internal_val2_1, v.IO_Internal_val2_2, v.IO_Internal_val2_3)
  

    fold dp.dp3s_iospec_bio3s_exit(s, t)
    fold dp.dp3s_iospec_ordered(s, t)
    fold SharedInv!< dp, y !>()
    ghost m.Unlock()
  }
  return pkt
}

/*
requires PktMem(p)
requires acc(m.LockP(), _) && m.LockInv() == SharedInv!< y !>;
requires IO_val_Abs(p).isIO_val_Pkt2
requires ElemWitness(y.IBufY, ID(ingressID), IO_val_Abs(p).IO_val_Pkt2_2)
requires IO_val_Abs(p).IO_val_Pkt2_1 == ID(ingressID)
func Process(p Pkt, ghost ingressID uint16, ghost m *sync.Mutex, ghost y SharedArg) {
    ghost pkt := IO_val_Abs(p)
    ghost newpkt, egressID := check(p)
    //assume pkt.IO_val_Pkt2_1 == ID(ingressID)
    //Inbound
    //enter

    ghost if ID(ingressID) != none[io.IO_ifs] { //we have to proof this 
        ghost pkt_internal := io.IO_Pkt2ToIO_Internal_val1(pkt)
        assert pkt_internal.IO_Internal_val1_2 == io.IO_ifs(ingressID)
        isXover := false //remove

        assume len(pkt_internal.IO_Internal_val1_1.CurrSeg.Future) > 0 //true by construction

        //updateNonConsDirIngressSegID
        //needed for io.dp3s_forward( ... )
        assume !pkt_internal.IO_Internal_val1_1.CurrSeg.ConsDir ==> pkt_internal.IO_Internal_val1_3.CurrSeg.UInfo == io.upd_uinfo(pkt_internal.IO_Internal_val1_1.CurrSeg.UInfo, pkt_internal.IO_Internal_val1_1.CurrSeg.Future[0])

       if isXover {
        //Xover
        //pkt_internal := IO_Pkt2ToIO_Internal_val2(pkt)
        //isXover
        assume pkt.IO_val_Pkt2_2.LeftSeg != none[io.IO_seg2]
        if pkt.IO_val_Pkt2_2.CurrSeg.ConsDir == get(pkt.IO_val_Pkt2_2.LeftSeg).ConsDir {
            //core
            ghost m.Lock()
            unfold SharedInv!< y !>()

            t, s := *y.Place, *y.State

            ApplyElemWitness(s.ibuf, y.IBufY, ID(ingressID), pkt.IO_val_Pkt2_2)
            assert pkt.IO_val_Pkt2_2 in AsSet(s.ibuf[ID(ingressID)])

            ghost v:= pkt_internal
            
            unfold io.dp3s_iospec_ordered(s, t)
	        unfold io.dp3s_iospec_bio3s_xover_core(s, t)
            assume io.asid() in io.core_as_set() //Check if core router
            
            currseg := v.IO_Internal_val1_1.CurrSeg
            nextseg := get(v.IO_Internal_val1_1.LeftSeg)
            assume len(nextseg.Future) > 0 //true by construction
            assume len(currseg.Future) > 0 //true by construction
            
            hf1, hf2 := currseg.Future[0], nextseg.Future[0]
            assume nextseg.History == seq[io.IO_ahi]{} //true by construction
            assume currseg.Future == seq[io.IO_HF]{hf1} //true by construction
            traversedseg := io.dp3s_iospec_bio3s_create_guard_traversedseg_inc(currseg)

            
            assert currseg.ConsDir == nextseg.ConsDir

            assume io.xover_core2_link_type(hf1, hf2, io.asid(), currseg.ConsDir) //simple
           
            //assume io.dp2_in_ext(s, io.asid(), v.Internal_val1_2, v.Internal_val1_1)
            
            assert some(v.IO_Internal_val1_2) in domain(s.ibuf)

            //validateIngressID
            assume currseg.ConsDir ==> hf1.InIF2 === some(v.IO_Internal_val1_2) 
            assume !currseg.ConsDir ==> hf1.EgIF2 === some(v.IO_Internal_val1_2)

            assume io.valid_link_types_in2(hf1, io.asid()) //true by construction
            assume io.valid_link_types2(hf1, io.asid()) //true by construction
            assert io.dp2_check_interface(currseg.ConsDir, io.asid(), hf1, v.IO_Internal_val1_2)
            assume io.dp2_check_recvif(currseg.ConsDir, io.asid(), v.IO_Internal_val1_2) //simple

            //verifyCurrentMAC()
            assume io.hf_valid(currseg.ConsDir, currseg.AInfo, traversedseg.UInfo, hf1)
            assume io.hf_valid(nextseg.ConsDir, nextseg.AInfo, nextseg.UInfo, hf2)
            assume hf1.extr_asid() == io.asid() && hf2.extr_asid() == io.asid()

            assert v.IO_Internal_val1_1.CurrSeg == currseg
			assert v.IO_Internal_val1_1.LeftSeg == some(nextseg)
			assert nextseg.History == seq[io.IO_ahi]{}
			//assert traversedseg == io.IO_pkt2(io.IO_Packet2{nextseg, v.IO_Internal_val1_1.MidSeg, v.IO_Internal_val1_1.RightSeg, some(traversedseg)})
			assert currseg.Future == seq[io.IO_HF]{hf1}
			assert len(nextseg.Future) > 0 
			assert nextseg.Future[0] == hf2
			assert io.dp2_check_interface(currseg.ConsDir, io.asid(), hf1, v.IO_Internal_val1_2)
			assert io.dp2_check_recvif(currseg.ConsDir, io.asid(), v.IO_Internal_val1_2)
			assert io.update_uinfo(!currseg.ConsDir, currseg, traversedseg, hf1) 
			assert io.inc_seg2(currseg, traversedseg, hf1, seq[io.IO_HF]{})
			assert io.hf_valid(currseg.ConsDir, currseg.AInfo, traversedseg.UInfo, hf1)
			assert io.hf_valid(nextseg.ConsDir, nextseg.AInfo, nextseg.UInfo, hf2)
			assert hf1.extr_asid() == io.asid() 
			assert hf2.extr_asid() == io.asid() 
			assert io.same_other2(currseg, traversedseg)
            assert io.dp3s_forward(
                io.IO_pkt2(io.IO_Packet2{nextseg, v.IO_Internal_val1_1.MidSeg, v.IO_Internal_val1_1.RightSeg, some(traversedseg)}),
                io.IO_pkt2(io.IO_Packet2{nextseg, v.IO_Internal_val1_1.MidSeg, v.IO_Internal_val1_1.RightSeg, some(traversedseg)}),
                v.IO_Internal_val1_4)

            pkt_internal := io.IO_val(io.IO_Internal_val1{
                pkt_internal.IO_Internal_val1_1, 
                pkt_internal.IO_Internal_val1_2, 
                io.IO_pkt2(io.IO_Packet2{nextseg, v.IO_Internal_val1_1.MidSeg, v.IO_Internal_val1_1.RightSeg, some(traversedseg)}), 
                pkt_internal.IO_Internal_val1_4, 
            })
            assert io.dp2_xover_common_guard(
                v.IO_Internal_val1_1,
                currseg,
                nextseg, 
                traversedseg, 
                io.IO_pkt2(io.IO_Packet2{nextseg, v.IO_Internal_val1_1.MidSeg, v.IO_Internal_val1_1.RightSeg, some(traversedseg)}),
                hf1, 
                hf2, 
                hf1.extr_asid(), 
                v.IO_Internal_val1_2)

            assert io.dp3s_iospec_bio3s_xover_core_guard(s, t, pkt_internal)

            tN := io.dp3s_iospec_bio3s_xover_core_T(t, pkt_internal)
            Xover_core(t, pkt_internal)

            UpdateElemWitness(s.obuf, y.OBufY, pkt_internal.IO_Internal_val1_4, pkt_internal.IO_Internal_val1_3)
            
            ghost *y.State = io.dp3s_add_obuf(s, pkt_internal.IO_Internal_val1_4, pkt_internal.IO_Internal_val1_3)
            ghost *y.Place = tN
            
            fold SharedInv!< y !>()
            ghost m.Unlock()

            
        } else {
            //up2down
            ghost m.Lock()
            unfold SharedInv!< y !>()

            t, s := *y.Place, *y.State

            ApplyElemWitness(s.ibuf, y.IBufY, ID(ingressID), pkt.IO_val_Pkt2_2)
            assert pkt.IO_val_Pkt2_2 in AsSet(s.ibuf[ID(ingressID)])

            ghost v:= pkt_internal
            
            unfold io.dp3s_iospec_ordered(s, t)
	        unfold io.dp3s_iospec_bio3s_xover_up2down(s, t)
            //assume io.asid() in io.core_as_set() //Check if core router
            
            currseg := v.IO_Internal_val1_1.CurrSeg
            nextseg := get(v.IO_Internal_val1_1.LeftSeg)
            assume len(nextseg.Future) > 0 //true by construction
            assume len(currseg.Future) > 0 //true by construction
            
            hf1, hf2 := currseg.Future[0], nextseg.Future[0]
            assume nextseg.History == seq[io.IO_ahi]{} //true by construction
            assume currseg.Future == seq[io.IO_HF]{hf1} //true by construction
            traversedseg := io.dp3s_iospec_bio3s_create_guard_traversedseg_inc(currseg)

            
            assume nextseg.ConsDir //we need to prove this

            assume io.xover_up2down2_link_type(io.asid(), hf1, hf2) //simple
           
            //assume io.dp2_in_ext(s, io.asid(), v.Internal_val1_2, v.Internal_val1_1)
            
            assert some(v.IO_Internal_val1_2) in domain(s.ibuf)

            //validateIngressID
            assume currseg.ConsDir ==> hf1.InIF2 === some(v.IO_Internal_val1_2) 
            assume !currseg.ConsDir ==> hf1.EgIF2 === some(v.IO_Internal_val1_2)

            assume io.valid_link_types_in2(hf1, io.asid()) //true by construction
            assume io.valid_link_types2(hf1, io.asid()) //true by construction
            assert io.dp2_check_interface(currseg.ConsDir, io.asid(), hf1, v.IO_Internal_val1_2)
            assume io.dp2_check_recvif(currseg.ConsDir, io.asid(), v.IO_Internal_val1_2) //simple

            //verifyCurrentMAC()
            assume io.hf_valid(currseg.ConsDir, currseg.AInfo, traversedseg.UInfo, hf1)
            assume io.hf_valid(nextseg.ConsDir, nextseg.AInfo, nextseg.UInfo, hf2)
            assume hf1.extr_asid() == io.asid() && hf2.extr_asid() == io.asid()

            assert v.IO_Internal_val1_1.CurrSeg == currseg
			assert v.IO_Internal_val1_1.LeftSeg == some(nextseg)
			assert nextseg.History == seq[io.IO_ahi]{}
			//assert traversedseg == io.IO_pkt2(io.IO_Packet2{nextseg, v.IO_Internal_val1_1.MidSeg, v.IO_Internal_val1_1.RightSeg, some(traversedseg)})
			assert currseg.Future == seq[io.IO_HF]{hf1}
			assert len(nextseg.Future) > 0 
			assert nextseg.Future[0] == hf2
			assert io.dp2_check_interface(currseg.ConsDir, io.asid(), hf1, v.IO_Internal_val1_2)
			assert io.dp2_check_recvif(currseg.ConsDir, io.asid(), v.IO_Internal_val1_2)
			assert io.update_uinfo(!currseg.ConsDir, currseg, traversedseg, hf1) 
			assert io.inc_seg2(currseg, traversedseg, hf1, seq[io.IO_HF]{})
			assert io.hf_valid(currseg.ConsDir, currseg.AInfo, traversedseg.UInfo, hf1)
			assert io.hf_valid(nextseg.ConsDir, nextseg.AInfo, nextseg.UInfo, hf2)
			assert hf1.extr_asid() == io.asid() 
			assert hf2.extr_asid() == io.asid() 
			assert io.same_other2(currseg, traversedseg)
            assert io.dp3s_forward(
                io.IO_pkt2(io.IO_Packet2{nextseg, v.IO_Internal_val1_1.MidSeg, v.IO_Internal_val1_1.RightSeg, some(traversedseg)}),
                io.IO_pkt2(io.IO_Packet2{nextseg, v.IO_Internal_val1_1.MidSeg, v.IO_Internal_val1_1.RightSeg, some(traversedseg)}),
                v.IO_Internal_val1_4)

            pkt_internal := io.IO_val(io.IO_Internal_val1{
                pkt_internal.IO_Internal_val1_1, 
                pkt_internal.IO_Internal_val1_2, 
                io.IO_pkt2(io.IO_Packet2{nextseg, v.IO_Internal_val1_1.MidSeg, v.IO_Internal_val1_1.RightSeg, some(traversedseg)}), 
                pkt_internal.IO_Internal_val1_4, 
            })
            assert io.dp2_xover_common_guard(
                v.IO_Internal_val1_1,
                currseg,
                nextseg, 
                traversedseg, 
                io.IO_pkt2(io.IO_Packet2{nextseg, v.IO_Internal_val1_1.MidSeg, v.IO_Internal_val1_1.RightSeg, some(traversedseg)}),
                hf1, 
                hf2, 
                hf1.extr_asid(), 
                v.IO_Internal_val1_2)

            assert io.dp3s_iospec_bio3s_xover_up2down_guard(s, t, pkt_internal)

            tN := io.dp3s_iospec_bio3s_xover_up2down_T(t, pkt_internal)
            Xover_up2down(t, pkt_internal)

            UpdateElemWitness(s.obuf, y.OBufY, pkt_internal.IO_Internal_val1_4, pkt_internal.IO_Internal_val1_3)
            
            ghost *y.State = io.dp3s_add_obuf(s, pkt_internal.IO_Internal_val1_4, pkt_internal.IO_Internal_val1_3)
            ghost *y.Place = tN
            
            fold SharedInv!< y !>()
            ghost m.Unlock()
        }

       } else {
        ghost m.Lock()
        unfold SharedInv!< y !>()

        t, s := *y.Place, *y.State

        ApplyElemWitness(s.ibuf, y.IBufY, ID(ingressID), pkt_internal.IO_Internal_val1_1)
	    assert  pkt_internal.IO_Internal_val1_1 in AsSet(s.ibuf[ID(ingressID)])

        ghost v:= pkt_internal
        assume len(v.IO_Internal_val1_1.CurrSeg.Future) > 0 //should be trivial to proof

        


        unfold io.dp3s_iospec_ordered(s, t)
	    unfold io.dp3s_iospec_bio3s_enter(s, t)
        assert some(pkt_internal.IO_Internal_val1_2) in domain(s.ibuf)
        assert (let ibuf_set := s.ibuf[some(v.IO_Internal_val1_2)] in (v.IO_Internal_val1_1 in ibuf_set))
        
        ghost currseg := v.IO_Internal_val1_1.CurrSeg
        ghost hf1, fut := currseg.Future[0], currseg.Future[1:]
        ghost traversedseg := io.dp3s_iospec_bio3s_create_guard_traversedseg(currseg)
        // assume io.dp2_enter_guard(
		// 	v.IO_Internal_val1_1,
		// 	currseg,
		// 	traversedseg,
		// 	io.asid(),
		// 	hf1,
		// 	v.IO_Internal_val1_2,
		// 	fut)
        assert v.IO_Internal_val1_1.CurrSeg == currseg
        assert currseg.Future == seq[io.IO_HF]{hf1} ++ fut
        assert io.update_uinfo(!currseg.ConsDir, currseg, traversedseg, hf1)
        assert io.same_segment2(currseg, traversedseg)
        assert io.same_other2(currseg, traversedseg)

        //validateIngressID
        assume currseg.ConsDir ==> hf1.InIF2 === some(v.IO_Internal_val1_2) 
        assume !currseg.ConsDir ==> hf1.EgIF2 === some(v.IO_Internal_val1_2)


        assume io.valid_link_types_in2(hf1, io.asid()) //true by construction
        assume io.valid_link_types2(hf1, io.asid()) //true by construction
        assert io.dp2_check_interface(currseg.ConsDir, io.asid(), hf1, v.IO_Internal_val1_2)
        
        //verifyCurrentMAC()
        assume io.hf_valid(currseg.ConsDir, currseg.AInfo, traversedseg.UInfo, hf1)

        assume hf1.extr_asid() == io.asid() //true by construction

        assert io.dp3s_iospec_bio3s_enter_guard(s, t, pkt_internal)

        tN := io.CBio_IN_bio3s_enter_T(t, pkt_internal)
        Enter(t, pkt_internal)

        UpdateElemWitness(s.obuf, y.OBufY, pkt_internal.IO_Internal_val1_4, pkt_internal.IO_Internal_val1_3)
        
        ghost *y.State = io.dp3s_add_obuf(s, pkt_internal.IO_Internal_val1_4, pkt_internal.IO_Internal_val1_3)
	    ghost *y.Place = tN
        
        fold SharedInv!< y !>()
        ghost m.Unlock()
       }
        

        
    } else {  //Outbound ------------------------------------------------------------
        assert ID(ingressID) == none[io.IO_ifs]
        pkt_internal := IO_Pkt2ToIO_Internal_val2(pkt)
        //exit  
        ghost m.Lock()
        unfold SharedInv!< y !>()

        t, s := *y.Place, *y.State

        ApplyElemWitness(s.ibuf, y.IBufY, ID(ingressID), pkt_internal.IO_Internal_val2_1)
	    assert pkt_internal.IO_Internal_val2_1 in AsSet(s.ibuf[ID(ingressID)])

        //ghost v:= pkt_internal
        //assume len(v.IO_Internal_val1_1.CurrSeg.Future) > 0 //should be trivial to proof

        assert io.dp3s_iospec_bio3s_exit_guard(s, t, pkt_internal)


        unfold io.dp3s_iospec_ordered(s, t)
	    unfold io.dp3s_iospec_bio3s_exit(s, t)

        tN := io.dp3s_iospec_bio3s_exit_T(t, pkt_internal)
        Exit(t, pkt_internal)

        UpdateElemWitness(s.obuf, y.OBufY, some(pkt_internal.IO_Internal_val2_3), pkt_internal.IO_Internal_val2_2)
        
        ghost *y.State = io.dp3s_add_obuf(s, some(pkt_internal.IO_Internal_val2_3), pkt_internal.IO_Internal_val2_2)
	    ghost *y.Place = tN
        
        fold SharedInv!< y !>()
        ghost m.Unlock()
    }
}*/